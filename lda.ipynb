{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"./CSV/data1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(fileName, error_bad_lines=False, encoding='latin-1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = data[['text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=2000, step=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text[\"index\"] = data_text.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text['datetime'] = data[['created_at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(data_text))\n",
    "# data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  index  \\\n",
      "0  Modi's Ayushman Bharat is born through caesare...      0   \n",
      "1  RT @centerofright: First claim made on #Ayushm...      1   \n",
      "2  RT @drdineshias: First claim raised under #Ayu...      2   \n",
      "3  RT @centerofright: First claim made on #Ayushm...      3   \n",
      "4  RT @centerofright: First claim made on #Ayushm...      4   \n",
      "5  First claim raised under Ayushman Bharat with ...      5   \n",
      "6  RT @SureshNakhua: #ModiCare aka Ayushman Bhara...      6   \n",
      "7  RT @centerofright: First claim made on #Ayushm...      7   \n",
      "8  RT @drdineshias: First claim raised under #Ayu...      8   \n",
      "9  AAP puts Ayushman Bharat for Delhi in jeopardy...      9   \n",
      "\n",
      "                         datetime  \n",
      "0  Sat Sep 01 23:58:23 +0000 2018  \n",
      "1  Sat Sep 01 23:56:53 +0000 2018  \n",
      "2  Sat Sep 01 23:54:54 +0000 2018  \n",
      "3  Sat Sep 01 23:53:54 +0000 2018  \n",
      "4  Sat Sep 01 23:52:37 +0000 2018  \n",
      "5  Sat Sep 01 23:48:16 +0000 2018  \n",
      "6  Sat Sep 01 23:44:36 +0000 2018  \n",
      "7  Sat Sep 01 23:44:14 +0000 2018  \n",
      "8  Sat Sep 01 23:42:51 +0000 2018  \n",
      "9  Sat Sep 01 23:36:07 +0000 2018  \n"
     ]
    }
   ],
   "source": [
    "print(document[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import nltk\n",
    "import numpy as np\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/sagban/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "#     stemmer = PorterStemmer()\n",
    "#     return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sleep'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(\"sleeps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_url(text):\n",
    "    result = re.sub(r\"http\\S+\", \"\", text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' dnkefnldwdj'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(\"https://sdemdsqn dnkefnldwdj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_user(t):\n",
    "    t = re.sub('@[^\\s]+','',t)\n",
    "    return re.sub('@[^\\s]+','',t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT  First claim made on'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rem_user(\"RT @centerofright: First claim made on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellcheck(text):\n",
    "    return  re.sub(r'[^a-z]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edennnswnefne'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spellcheck(\"edennnswn#21efne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = remove_url(text)\n",
    "    text = rem_user(text)\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            lem = lemmatize(token)\n",
    "            spl = spellcheck(lem)\n",
    "            if len(spl) > 2:\n",
    "                result.append(spl)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['claim']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"RT @centerofright: First claim made on23 https://hghh.vojmn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['Two', 'days', 'after', 'launch,', 'Ayushman', 'Bharat', 'has', 'its', 'first', 'baby:\\x8cæKarishma', 'https://t.co/IFOr6wszS7', 'https://t.co/bbu3EjzJVc']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['days', 'launch', 'ayushman', 'bharat', 'baby', 'karishma']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = document['text'][23]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = document\n",
    "processed_docs['text'] = processed_docs['text'].map(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>index</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[modi, ayushman, bharat, bear, caesarean, sect...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Sep 01 23:58:23 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[claim, ayushmanbharat, great, start, modicare...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sat Sep 01 23:56:53 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[claim, raise, ayushmanbharat, baby, girl, bea...</td>\n",
       "      <td>2</td>\n",
       "      <td>Sat Sep 01 23:54:54 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[claim, ayushmanbharat, great, start, modicare...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sat Sep 01 23:53:54 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[claim, ayushmanbharat, great, start, modicare...</td>\n",
       "      <td>4</td>\n",
       "      <td>Sat Sep 01 23:52:37 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[claim, raise, ayushman, bharat, birth, girl, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Sat Sep 01 23:48:16 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[modicare, ayushman, bharat, bear, caesarean, ...</td>\n",
       "      <td>6</td>\n",
       "      <td>Sat Sep 01 23:44:36 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[claim, ayushmanbharat, great, start, modicare...</td>\n",
       "      <td>7</td>\n",
       "      <td>Sat Sep 01 23:44:14 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[claim, raise, ayushmanbharat, baby, girl, bea...</td>\n",
       "      <td>8</td>\n",
       "      <td>Sat Sep 01 23:42:51 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[put, ayushman, bharat, delhi, jeopardy, deman...</td>\n",
       "      <td>9</td>\n",
       "      <td>Sat Sep 01 23:36:07 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[claim, ayushmanbharat, great, start, modicare...</td>\n",
       "      <td>10</td>\n",
       "      <td>Sat Sep 01 23:33:02 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[claim, ayushmanbharat, great, start, modicare...</td>\n",
       "      <td>11</td>\n",
       "      <td>Sat Sep 01 23:30:42 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[claim, ayushmanbharat, great, start, modicare...</td>\n",
       "      <td>12</td>\n",
       "      <td>Sat Sep 01 23:28:20 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[claim, ayushmanbharat, great, start, modicare...</td>\n",
       "      <td>13</td>\n",
       "      <td>Sat Sep 01 23:27:25 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[claim, ayushmanbharat, great, start, modicare...</td>\n",
       "      <td>14</td>\n",
       "      <td>Sat Sep 01 23:24:16 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[claim, ayushmanbharat, great, start, modicare...</td>\n",
       "      <td>15</td>\n",
       "      <td>Sat Sep 01 23:23:13 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[claim, ayushmanbharat, great, start, modicare...</td>\n",
       "      <td>16</td>\n",
       "      <td>Sat Sep 01 23:20:40 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[claim, raise, ayushmanbharat, baby, girl, bea...</td>\n",
       "      <td>17</td>\n",
       "      <td>Sat Sep 01 23:19:07 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[claim, ayushmanbharat, great, start, modicare...</td>\n",
       "      <td>18</td>\n",
       "      <td>Sat Sep 01 23:16:15 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[modicare, claim, raise, ayushmanbharat, today...</td>\n",
       "      <td>19</td>\n",
       "      <td>Sat Sep 01 23:14:54 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[mission, director, organise, yoga, encouragem...</td>\n",
       "      <td>20</td>\n",
       "      <td>Sat Sep 01 23:14:34 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[claim, ayushmanbharat, great, start, modicare...</td>\n",
       "      <td>21</td>\n",
       "      <td>Sat Sep 01 23:07:59 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[days, launch, ayushman, bharat, baby, karishma]</td>\n",
       "      <td>22</td>\n",
       "      <td>Sat Sep 01 23:05:52 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[days, launch, ayushman, bharat, baby, karishma]</td>\n",
       "      <td>23</td>\n",
       "      <td>Sat Sep 01 23:05:24 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[claim, raise, ayushmanbharat, baby, girl, bea...</td>\n",
       "      <td>24</td>\n",
       "      <td>Sat Sep 01 23:04:07 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[claim, ayushmanbharat, great, start, modicare...</td>\n",
       "      <td>25</td>\n",
       "      <td>Sat Sep 01 23:03:36 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[claim, ayushmanbharat, great, start, modicare...</td>\n",
       "      <td>26</td>\n",
       "      <td>Sat Sep 01 23:02:29 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[claim, raise, ayushmanbharat, baby, girl, bea...</td>\n",
       "      <td>27</td>\n",
       "      <td>Sat Sep 01 22:58:18 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[claim, raise, ayushmanbharat, baby, girl, bea...</td>\n",
       "      <td>28</td>\n",
       "      <td>Sat Sep 01 22:49:36 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[mega, health, plan, cripple, insist, flagship...</td>\n",
       "      <td>29</td>\n",
       "      <td>Sat Sep 01 22:46:09 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>[ayushma, plan, typical, modi, idea, impossibl...</td>\n",
       "      <td>1970</td>\n",
       "      <td>Tue Sep 04 04:54:57 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>[, , , , , , , , , , , namo, app]</td>\n",
       "      <td>1971</td>\n",
       "      <td>Tue Sep 04 04:54:47 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>[claim, raise, ayushmanbharat, baby, girl, bea...</td>\n",
       "      <td>1972</td>\n",
       "      <td>Tue Sep 04 04:53:45 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>[karishma, karnal, india, ayushmanbharat, bene...</td>\n",
       "      <td>1973</td>\n",
       "      <td>Tue Sep 04 04:52:50 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>[pragati, session, today, review, aspects, rel...</td>\n",
       "      <td>1974</td>\n",
       "      <td>Tue Sep 04 04:52:35 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>[pragati, session, today, review, aspects, rel...</td>\n",
       "      <td>1975</td>\n",
       "      <td>Tue Sep 04 04:52:35 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>[haryana, girl, india, newborn, beneficiary, a...</td>\n",
       "      <td>1976</td>\n",
       "      <td>Tue Sep 04 04:52:07 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>[write, prophesy, ayushman, bharat, health, in...</td>\n",
       "      <td>1977</td>\n",
       "      <td>Tue Sep 04 04:50:09 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>[haryana, days, karishma, bear, kalpana, chawl...</td>\n",
       "      <td>1978</td>\n",
       "      <td>Tue Sep 04 04:47:40 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>[claim, raise, ayushmanbharat, baby, girl, bea...</td>\n",
       "      <td>1979</td>\n",
       "      <td>Tue Sep 04 04:46:39 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>[karishma, karnal, india, ayushmanbharat, bene...</td>\n",
       "      <td>1980</td>\n",
       "      <td>Tue Sep 04 04:45:28 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>[baby, angel, ayushman, yojna, haryana, baby, ...</td>\n",
       "      <td>1981</td>\n",
       "      <td>Tue Sep 04 04:43:45 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>[haryana, girl, india, newborn, beneficiary, a...</td>\n",
       "      <td>1982</td>\n",
       "      <td>Tue Sep 04 04:41:51 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>[build, toilets, modi, admi, vulnerable, disea...</td>\n",
       "      <td>1983</td>\n",
       "      <td>Tue Sep 04 04:40:07 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>[haryana, girl, india, newborn, beneficiary, a...</td>\n",
       "      <td>1984</td>\n",
       "      <td>Tue Sep 04 04:39:51 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>[bear, independence, haryana, girl, india, new...</td>\n",
       "      <td>1985</td>\n",
       "      <td>Tue Sep 04 04:39:45 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>[haryana, girl, india, newborn, beneficiary, a...</td>\n",
       "      <td>1986</td>\n",
       "      <td>Tue Sep 04 04:38:03 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>[haryana, girl, india, newborn, beneficiary, a...</td>\n",
       "      <td>1987</td>\n",
       "      <td>Tue Sep 04 04:37:53 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>[haryana, girl, india, newborn, beneficiary, a...</td>\n",
       "      <td>1988</td>\n",
       "      <td>Tue Sep 04 04:37:40 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>[haryana, girl, india, newborn, beneficiary, a...</td>\n",
       "      <td>1989</td>\n",
       "      <td>Tue Sep 04 04:37:04 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>[pilot, ayushman, bharat, yojana, go, inaugura...</td>\n",
       "      <td>1990</td>\n",
       "      <td>Tue Sep 04 04:33:01 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>[claim, raise, ayushmanbharat, baby, girl, bea...</td>\n",
       "      <td>1991</td>\n",
       "      <td>Tue Sep 04 04:32:24 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>[haryana, girl, india, newborn, beneficiary, a...</td>\n",
       "      <td>1992</td>\n",
       "      <td>Tue Sep 04 04:31:11 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>[haryana, girl, india, newborn, beneficiary, a...</td>\n",
       "      <td>1993</td>\n",
       "      <td>Tue Sep 04 04:30:03 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>[pilot, ayushman, bharat, yojana, go, inaugura...</td>\n",
       "      <td>1994</td>\n",
       "      <td>Tue Sep 04 04:28:51 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>[bear, independence, haryana, girl, india, new...</td>\n",
       "      <td>1995</td>\n",
       "      <td>Tue Sep 04 04:27:18 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>[haryana, girl, india, newborn, beneficiary, a...</td>\n",
       "      <td>1996</td>\n",
       "      <td>Tue Sep 04 04:25:55 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>[karishma, karnal, india, ayushmanbharat, bene...</td>\n",
       "      <td>1997</td>\n",
       "      <td>Tue Sep 04 04:25:27 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>[haryana, girl, india, newborn, beneficiary, a...</td>\n",
       "      <td>1998</td>\n",
       "      <td>Tue Sep 04 04:24:39 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>[doctor, think, price, healthcare, business, s...</td>\n",
       "      <td>1999</td>\n",
       "      <td>Tue Sep 04 04:23:56 +0000 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  index  \\\n",
       "0     [modi, ayushman, bharat, bear, caesarean, sect...      0   \n",
       "1     [claim, ayushmanbharat, great, start, modicare...      1   \n",
       "2     [claim, raise, ayushmanbharat, baby, girl, bea...      2   \n",
       "3     [claim, ayushmanbharat, great, start, modicare...      3   \n",
       "4     [claim, ayushmanbharat, great, start, modicare...      4   \n",
       "5     [claim, raise, ayushman, bharat, birth, girl, ...      5   \n",
       "6     [modicare, ayushman, bharat, bear, caesarean, ...      6   \n",
       "7     [claim, ayushmanbharat, great, start, modicare...      7   \n",
       "8     [claim, raise, ayushmanbharat, baby, girl, bea...      8   \n",
       "9     [put, ayushman, bharat, delhi, jeopardy, deman...      9   \n",
       "10    [claim, ayushmanbharat, great, start, modicare...     10   \n",
       "11    [claim, ayushmanbharat, great, start, modicare...     11   \n",
       "12    [claim, ayushmanbharat, great, start, modicare...     12   \n",
       "13    [claim, ayushmanbharat, great, start, modicare...     13   \n",
       "14    [claim, ayushmanbharat, great, start, modicare...     14   \n",
       "15    [claim, ayushmanbharat, great, start, modicare...     15   \n",
       "16    [claim, ayushmanbharat, great, start, modicare...     16   \n",
       "17    [claim, raise, ayushmanbharat, baby, girl, bea...     17   \n",
       "18    [claim, ayushmanbharat, great, start, modicare...     18   \n",
       "19    [modicare, claim, raise, ayushmanbharat, today...     19   \n",
       "20    [mission, director, organise, yoga, encouragem...     20   \n",
       "21    [claim, ayushmanbharat, great, start, modicare...     21   \n",
       "22     [days, launch, ayushman, bharat, baby, karishma]     22   \n",
       "23     [days, launch, ayushman, bharat, baby, karishma]     23   \n",
       "24    [claim, raise, ayushmanbharat, baby, girl, bea...     24   \n",
       "25    [claim, ayushmanbharat, great, start, modicare...     25   \n",
       "26    [claim, ayushmanbharat, great, start, modicare...     26   \n",
       "27    [claim, raise, ayushmanbharat, baby, girl, bea...     27   \n",
       "28    [claim, raise, ayushmanbharat, baby, girl, bea...     28   \n",
       "29    [mega, health, plan, cripple, insist, flagship...     29   \n",
       "...                                                 ...    ...   \n",
       "1970  [ayushma, plan, typical, modi, idea, impossibl...   1970   \n",
       "1971                  [, , , , , , , , , , , namo, app]   1971   \n",
       "1972  [claim, raise, ayushmanbharat, baby, girl, bea...   1972   \n",
       "1973  [karishma, karnal, india, ayushmanbharat, bene...   1973   \n",
       "1974  [pragati, session, today, review, aspects, rel...   1974   \n",
       "1975  [pragati, session, today, review, aspects, rel...   1975   \n",
       "1976  [haryana, girl, india, newborn, beneficiary, a...   1976   \n",
       "1977  [write, prophesy, ayushman, bharat, health, in...   1977   \n",
       "1978  [haryana, days, karishma, bear, kalpana, chawl...   1978   \n",
       "1979  [claim, raise, ayushmanbharat, baby, girl, bea...   1979   \n",
       "1980  [karishma, karnal, india, ayushmanbharat, bene...   1980   \n",
       "1981  [baby, angel, ayushman, yojna, haryana, baby, ...   1981   \n",
       "1982  [haryana, girl, india, newborn, beneficiary, a...   1982   \n",
       "1983  [build, toilets, modi, admi, vulnerable, disea...   1983   \n",
       "1984  [haryana, girl, india, newborn, beneficiary, a...   1984   \n",
       "1985  [bear, independence, haryana, girl, india, new...   1985   \n",
       "1986  [haryana, girl, india, newborn, beneficiary, a...   1986   \n",
       "1987  [haryana, girl, india, newborn, beneficiary, a...   1987   \n",
       "1988  [haryana, girl, india, newborn, beneficiary, a...   1988   \n",
       "1989  [haryana, girl, india, newborn, beneficiary, a...   1989   \n",
       "1990  [pilot, ayushman, bharat, yojana, go, inaugura...   1990   \n",
       "1991  [claim, raise, ayushmanbharat, baby, girl, bea...   1991   \n",
       "1992  [haryana, girl, india, newborn, beneficiary, a...   1992   \n",
       "1993  [haryana, girl, india, newborn, beneficiary, a...   1993   \n",
       "1994  [pilot, ayushman, bharat, yojana, go, inaugura...   1994   \n",
       "1995  [bear, independence, haryana, girl, india, new...   1995   \n",
       "1996  [haryana, girl, india, newborn, beneficiary, a...   1996   \n",
       "1997  [karishma, karnal, india, ayushmanbharat, bene...   1997   \n",
       "1998  [haryana, girl, india, newborn, beneficiary, a...   1998   \n",
       "1999  [doctor, think, price, healthcare, business, s...   1999   \n",
       "\n",
       "                            datetime  \n",
       "0     Sat Sep 01 23:58:23 +0000 2018  \n",
       "1     Sat Sep 01 23:56:53 +0000 2018  \n",
       "2     Sat Sep 01 23:54:54 +0000 2018  \n",
       "3     Sat Sep 01 23:53:54 +0000 2018  \n",
       "4     Sat Sep 01 23:52:37 +0000 2018  \n",
       "5     Sat Sep 01 23:48:16 +0000 2018  \n",
       "6     Sat Sep 01 23:44:36 +0000 2018  \n",
       "7     Sat Sep 01 23:44:14 +0000 2018  \n",
       "8     Sat Sep 01 23:42:51 +0000 2018  \n",
       "9     Sat Sep 01 23:36:07 +0000 2018  \n",
       "10    Sat Sep 01 23:33:02 +0000 2018  \n",
       "11    Sat Sep 01 23:30:42 +0000 2018  \n",
       "12    Sat Sep 01 23:28:20 +0000 2018  \n",
       "13    Sat Sep 01 23:27:25 +0000 2018  \n",
       "14    Sat Sep 01 23:24:16 +0000 2018  \n",
       "15    Sat Sep 01 23:23:13 +0000 2018  \n",
       "16    Sat Sep 01 23:20:40 +0000 2018  \n",
       "17    Sat Sep 01 23:19:07 +0000 2018  \n",
       "18    Sat Sep 01 23:16:15 +0000 2018  \n",
       "19    Sat Sep 01 23:14:54 +0000 2018  \n",
       "20    Sat Sep 01 23:14:34 +0000 2018  \n",
       "21    Sat Sep 01 23:07:59 +0000 2018  \n",
       "22    Sat Sep 01 23:05:52 +0000 2018  \n",
       "23    Sat Sep 01 23:05:24 +0000 2018  \n",
       "24    Sat Sep 01 23:04:07 +0000 2018  \n",
       "25    Sat Sep 01 23:03:36 +0000 2018  \n",
       "26    Sat Sep 01 23:02:29 +0000 2018  \n",
       "27    Sat Sep 01 22:58:18 +0000 2018  \n",
       "28    Sat Sep 01 22:49:36 +0000 2018  \n",
       "29    Sat Sep 01 22:46:09 +0000 2018  \n",
       "...                              ...  \n",
       "1970  Tue Sep 04 04:54:57 +0000 2018  \n",
       "1971  Tue Sep 04 04:54:47 +0000 2018  \n",
       "1972  Tue Sep 04 04:53:45 +0000 2018  \n",
       "1973  Tue Sep 04 04:52:50 +0000 2018  \n",
       "1974  Tue Sep 04 04:52:35 +0000 2018  \n",
       "1975  Tue Sep 04 04:52:35 +0000 2018  \n",
       "1976  Tue Sep 04 04:52:07 +0000 2018  \n",
       "1977  Tue Sep 04 04:50:09 +0000 2018  \n",
       "1978  Tue Sep 04 04:47:40 +0000 2018  \n",
       "1979  Tue Sep 04 04:46:39 +0000 2018  \n",
       "1980  Tue Sep 04 04:45:28 +0000 2018  \n",
       "1981  Tue Sep 04 04:43:45 +0000 2018  \n",
       "1982  Tue Sep 04 04:41:51 +0000 2018  \n",
       "1983  Tue Sep 04 04:40:07 +0000 2018  \n",
       "1984  Tue Sep 04 04:39:51 +0000 2018  \n",
       "1985  Tue Sep 04 04:39:45 +0000 2018  \n",
       "1986  Tue Sep 04 04:38:03 +0000 2018  \n",
       "1987  Tue Sep 04 04:37:53 +0000 2018  \n",
       "1988  Tue Sep 04 04:37:40 +0000 2018  \n",
       "1989  Tue Sep 04 04:37:04 +0000 2018  \n",
       "1990  Tue Sep 04 04:33:01 +0000 2018  \n",
       "1991  Tue Sep 04 04:32:24 +0000 2018  \n",
       "1992  Tue Sep 04 04:31:11 +0000 2018  \n",
       "1993  Tue Sep 04 04:30:03 +0000 2018  \n",
       "1994  Tue Sep 04 04:28:51 +0000 2018  \n",
       "1995  Tue Sep 04 04:27:18 +0000 2018  \n",
       "1996  Tue Sep 04 04:25:55 +0000 2018  \n",
       "1997  Tue Sep 04 04:25:27 +0000 2018  \n",
       "1998  Tue Sep 04 04:24:39 +0000 2018  \n",
       "1999  Tue Sep 04 04:23:56 +0000 2018  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ayushman\n",
      "1 bear\n",
      "2 bharat\n",
      "3 caesarean\n",
      "4 economic\n",
      "5 modi\n",
      "6 section\n",
      "7 time\n",
      "8 ayushmanbharat\n",
      "9 birth\n",
      "10 claim\n",
      "11 fittingly\n",
      "12 girl\n",
      "13 great\n",
      "14 modicare\n",
      "15 start\n",
      "16 baby\n",
      "17 chawla\n",
      "18 hary\n",
      "19 hospital\n",
      "20 kalpana\n",
      "21 raise\n",
      "22 haryana\n",
      "23 delhi\n",
      "24 demand\n",
      "25 jeopardy\n",
      "26 party\n",
      "27 put\n",
      "28 scheme\n",
      "29 kal\n",
      "30 today\n",
      "31 director\n",
      "32 encouragement\n",
      "33 healthy\n",
      "34 learn\n",
      "35 lifestyle\n",
      "36 mission\n",
      "37 organise\n",
      "38 par\n",
      "39 yoga\n",
      "40 days\n",
      "41 karishma\n",
      "42 launch\n",
      "43 abpmjay\n",
      "44 arogya\n",
      "45 cripple\n",
      "46 flagship\n",
      "47 health\n",
      "48 insist\n",
      "49 mantri\n",
      "50 mega\n",
      "51 plan\n",
      "52 pradhan\n",
      "53 yojna\n",
      "54 all\n",
      "55 bank\n",
      "56 direct\n",
      "57 house\n",
      "58 loan\n",
      "59 mudhra\n",
      "60 payment\n",
      "61 power\n",
      "62 transfer\n",
      "63 arrive\n",
      "64 beneficiary\n",
      "65 congrats\n",
      "66 karnal\n",
      "67 proud\n",
      "68 aspects\n",
      "69 infrastructure\n",
      "70 pragati\n",
      "71 proj\n",
      "72 relate\n",
      "73 review\n",
      "74 session\n",
      "75 biggest\n",
      "76 care\n",
      "77 cover\n",
      "78 finance\n",
      "79 insurance\n",
      "80 lakh\n",
      "81 offer\n",
      "82 take\n",
      "83 whic\n",
      "84 world\n",
      "85 focus\n",
      "86 meet\n",
      "87 comment\n",
      "88 step\n",
      "89 cancer\n",
      "90 jagannath\n",
      "91 need\n",
      "92 odisha\n",
      "93 pecent\n",
      "94 state\n",
      "95 treatment\n",
      "96 stay\n",
      "97 want\n",
      "98 face\n",
      "99 opposition\n",
      "100 slap\n",
      "101 tight\n",
      "102 arvind\n",
      "103 gov\n",
      "104 implement\n",
      "105 kejriwal\n",
      "106 mukhya\n",
      "107 refuse\n",
      "108 rename\n",
      "109 yojana\n",
      "110 engvind\n",
      "111 indvspak\n",
      "112 highlight\n",
      "113 india\n",
      "114 jaw\n",
      "115 kumar\n",
      "116 panel\n",
      "117 pradeep\n",
      "118 prin\n",
      "119 vyas\n",
      "120 mother\n",
      "121 news\n",
      "122 todays\n",
      "123 has\n",
      "124 hospita\n",
      "125 public\n",
      "126 auspicious\n",
      "127 fantastic\n",
      "128 genworks\n",
      "129 healthier\n",
      "130 support\n",
      "131 work\n",
      "132 cesarean\n",
      "133 callousness\n",
      "134 government\n",
      "135 implementation\n",
      "136 know\n",
      "137 people\n",
      "138 show\n",
      "139 ambitious\n",
      "140 govt\n",
      "141 highly\n",
      "142 confuse\n",
      "143 get\n",
      "144 grand\n",
      "145 hard\n",
      "146 soft\n",
      "147 what\n",
      "148 deliveries\n",
      "149 happen\n",
      "150 janani\n",
      "151 simple\n",
      "152 suraksha\n",
      "153 narendra\n",
      "154 settle\n",
      "155 eligibility\n",
      "156 entitlement\n",
      "157 come\n",
      "158 ensure\n",
      "159 poor\n",
      "160 sector\n",
      "161 top\n",
      "162 transform\n",
      "163 administrator\n",
      "164 advertisement\n",
      "165 assam\n",
      "166 automatically\n",
      "167 double\n",
      "168 human\n",
      "169 lot\n",
      "170 make\n",
      "171 resources\n",
      "172 insura\n",
      "173 pioneerhealth\n",
      "174 saturday\n",
      "175 register\n",
      "176 ins\n",
      "177 august\n",
      "178 benefic\n",
      "179 celebrity\n",
      "180 bene\n",
      "181 attain\n",
      "182 status\n",
      "183 ayushmaanbharat\n",
      "184 billion\n",
      "185 bless\n",
      "186 elect\n",
      "187 indians\n",
      "188 hearten\n",
      "189 increase\n",
      "190 spend\n",
      "191 amit\n",
      "192 father\n",
      "193 kum\n",
      "194 celeb\n",
      "195 cool\n",
      "196 create\n",
      "197 devi\n",
      "198 golden\n",
      "199 platform\n",
      "200 record\n",
      "201 rudraprayag\n",
      "202 tara\n",
      "203 avoid\n",
      "204 future\n",
      "205 kichdi\n",
      "206 months\n",
      "207 sarkar\n",
      "208 tide\n",
      "209 turn\n",
      "210 abash\n",
      "211 amrapa\n",
      "212 buyers\n",
      "213 city\n",
      "214 digital\n",
      "215 home\n",
      "216 rera\n",
      "217 smart\n",
      "218 stress\n",
      "219 swachh\n",
      "220 yojona\n",
      "221 best\n",
      "222 body\n",
      "223 doorstep\n",
      "224 frankly\n",
      "225 local\n",
      "226 mobilize\n",
      "227 reach\n",
      "228 representatives\n",
      "229 agency\n",
      "230 beneficiaries\n",
      "231 centre\n",
      "232 common\n",
      "233 national\n",
      "234 service\n",
      "235 sign\n",
      "236 validation\n",
      "237 verification\n",
      "238 procedure\n",
      "239 unable\n",
      "240 understand\n",
      "241 benefit\n",
      "242 certain\n",
      "243 identification\n",
      "244 procedures\n",
      "245 congratulations\n",
      "246 fee\n",
      "247 google\n",
      "248 share\n",
      "249 deny\n",
      "250 program\n",
      "251 bristle\n",
      "252 critics\n",
      "253 jumla\n",
      "254 myth\n",
      "255 popularly\n",
      "256 realit\n",
      "257 separate\n",
      "258 bengaluru\n",
      "259 college\n",
      "260 discuss\n",
      "261 hemant\n",
      "262 accept\n",
      "263 center\n",
      "264 index\n",
      "265 problem\n",
      "266 hole\n",
      "267 needy\n",
      "268 real\n",
      "269 see\n",
      "270 website\n",
      "271 con\n",
      "272 appease\n",
      "273 interest\n",
      "274 pmjay\n",
      "275 private\n",
      "276 district\n",
      "277 minister\n",
      "278 narendramod\n",
      "279 prime\n",
      "280 account\n",
      "281 lakhs\n",
      "282 naxal\n",
      "283 promise\n",
      "284 refill\n",
      "285 ujjwala\n",
      "286 urban\n",
      "287 alipuram\n",
      "288 inaugurate\n",
      "289 mainly\n",
      "290 upgrade\n",
      "291 vizag\n",
      "292 wellness\n",
      "293 ben\n",
      "294 modiji\n",
      "295 parent\n",
      "296 child\n",
      "297 expense\n",
      "298 like\n",
      "299 arogaya\n",
      "300 central\n",
      "301 govts\n",
      "302 hurdle\n",
      "303 minute\n",
      "304 roll\n",
      "305 week\n",
      "306 break\n",
      "307 caesar\n",
      "308 path\n",
      "309 angiography\n",
      "310 angioplasty\n",
      "311 correct\n",
      "312 information\n",
      "313 not\n",
      "314 publish\n",
      "315 stent\n",
      "316 chief\n",
      "317 join\n",
      "318 missi\n",
      "319 naveen\n",
      "320 patnaik\n",
      "321 proposal\n",
      "322 protection\n",
      "323 reject\n",
      "324 newborn\n",
      "325 namo\n",
      "326 protec\n",
      "327 angel\n",
      "328 balrampur\n",
      "329 pilot\n",
      "330 tomorrow\n",
      "331 business\n",
      "332 cost\n",
      "333 doctor\n",
      "334 earful\n",
      "335 healthcare\n",
      "336 price\n",
      "337 slash\n",
      "338 sure\n",
      "339 think\n",
      "340 nam\n",
      "341 allege\n",
      "342 fraud\n",
      "343 selection\n",
      "344 staff\n",
      "345 comprehensive\n",
      "346 ayushma\n",
      "347 idea\n",
      "348 impossible\n",
      "349 overnight\n",
      "350 revolution\n",
      "351 sound\n",
      "352 target\n",
      "353 typical\n",
      "354 nmapp\n",
      "355 auto\n",
      "356 erfllen\n",
      "357 erste\n",
      "358 indiens\n",
      "359 pickup\n",
      "360 wikyou\n",
      "361 independence\n",
      "362 ahead\n",
      "363 formal\n",
      "364 hopefully\n",
      "365 launc\n",
      "366 process\n",
      "367 settlement\n",
      "368 stabilize\n",
      "369 systems\n",
      "370 trials\n",
      "371 htt\n",
      "372 modijifor\n",
      "373 bhar\n",
      "374 medical\n",
      "375 policy\n",
      "376 incomplete\n",
      "377 thankyou\n",
      "378 urge\n",
      "379 healthyindia\n",
      "380 ache\n",
      "381 kind\n",
      "382 list\n",
      "383 night\n",
      "384 tell\n",
      "385 visit\n",
      "386 wait\n",
      "387 year\n",
      "388 feasible\n",
      "389 model\n",
      "390 popul\n",
      "391 propose\n",
      "392 project\n",
      "393 style\n",
      "394 latestnews\n",
      "395 for\n",
      "396 hour\n",
      "397 ready\n",
      "398 slashing\n",
      "399 rsquo\n",
      "400 perform\n",
      "401 assembly\n",
      "402 convenor\n",
      "403 kavali\n",
      "404 mannepalli\n",
      "405 media\n",
      "406 social\n",
      "407 venkateswarlu\n",
      "408 prakashjavdekar\n",
      "409 ask\n",
      "410 dude\n",
      "411 everybody\n",
      "412 farm\n",
      "413 reservation\n",
      "414 waiver\n",
      "415 adhar\n",
      "416 allow\n",
      "417 and\n",
      "418 card\n",
      "419 link\n",
      "420 request\n",
      "421 victim\n",
      "422 experience\n",
      "423 gettin\n",
      "424 issue\n",
      "425 kerela\n",
      "426 podcast\n",
      "427 coverage\n",
      "428 fast\n",
      "429 initiatives\n",
      "430 monday\n",
      "431 nadda\n",
      "432 say\n",
      "433 track\n",
      "434 union\n",
      "435 universal\n",
      "436 call\n",
      "437 aarogya\n",
      "438 abhiyaan\n",
      "439 crore\n",
      "440 live\n",
      "441 middl\n",
      "442 devote\n",
      "443 fully\n",
      "444 wel\n",
      "445 advert\n",
      "446 events\n",
      "447 free\n",
      "448 medtech\n",
      "449 medtekon\n",
      "450 mtai\n",
      "451 venues\n",
      "452 hospitals\n",
      "453 opportunity\n",
      "454 class\n",
      "455 tha\n",
      "456 analysis\n",
      "457 columnist\n",
      "458 critical\n",
      "459 nitya\n",
      "460 pahuja\n",
      "461 dadra\n",
      "462 haveli\n",
      "463 nagar\n",
      "464 base\n",
      "465 insuran\n",
      "466 merge\n",
      "467 aadhar\n",
      "468 exclusive\n",
      "469 gpon\n",
      "470 interview\n",
      "471 society\n",
      "472 app\n",
      "473 ambi\n",
      "474 complete\n",
      "475 detail\n",
      "476 notification\n",
      "477 update\n",
      "478 awasidhi\n",
      "479 cap\n",
      "480 cheap\n",
      "481 generic\n",
      "482 include\n",
      "483 kendra\n",
      "484 medicine\n",
      "485 store\n",
      "486 che\n",
      "487 healthiness\n",
      "488 pmch\n",
      "489 kannadanews\n",
      "490 karnataka\n",
      "491 dirty\n",
      "492 politics\n",
      "493 janardan\n",
      "494 mela\n",
      "495 poojari\n",
      "496 visible\n",
      "497 wasn\n",
      "498 aim\n",
      "499 expand\n",
      "500 newindia\n",
      "501 preventi\n",
      "502 primary\n",
      "503 shri\n",
      "504 ahuja\n",
      "505 barwala\n",
      "506 farmer\n",
      "507 hisar\n",
      "508 kamal\n",
      "509 karnalrst\n",
      "510 respect\n",
      "511 small\n",
      "512 pradhanmantri\n",
      "513 medicare\n",
      "514 pathbreaking\n",
      "515 corner\n",
      "516 forward\n",
      "517 hearing\n",
      "518 look\n",
      "519 speaker\n",
      "520 vitalize\n",
      "521 brand\n",
      "522 develop\n",
      "523 swasth\n",
      "524 things\n",
      "525 whats\n",
      "526 different\n",
      "527 specialities\n",
      "528 bearing\n",
      "529 lucknow\n",
      "530 anti\n",
      "531 mudra\n",
      "532 oppose\n",
      "533 pmay\n",
      "534 policies\n",
      "535 unfortunate\n",
      "536 effect\n",
      "537 impact\n",
      "538 massive\n",
      "539 nation\n",
      "540 cgbjp\n",
      "541 modifor\n",
      "542 progress\n",
      "543 read\n",
      "544 laughable\n",
      "545 negligence\n",
      "546 cough\n",
      "547 abhinandan\n",
      "548 ayus\n",
      "549 chatra\n",
      "550 chhatra\n",
      "551 guru\n",
      "552 honour\n",
      "553 parishad\n",
      "554 students\n",
      "555 teachers\n",
      "556 vandan\n",
      "557 vikas\n",
      "558 aushmanbharat\n",
      "559 dont\n",
      "560 huge\n",
      "561 cashless\n",
      "562 block\n",
      "563 good\n",
      "564 modica\n",
      "565 via\n",
      "566 operate\n",
      "567 provide\n",
      "568 tertiary\n",
      "569 trust\n",
      "570 task\n",
      "571 couldnot\n",
      "572 download\n",
      "573 alternative\n",
      "574 diesel\n",
      "575 jump\n",
      "576 petrol\n",
      "577 till\n",
      "578 assurance\n",
      "579 bulk\n",
      "580 country\n",
      "581 line\n",
      "582 population\n",
      "583 poverty\n",
      "584 effective\n",
      "585 expenditure\n",
      "586 pocket\n",
      "587 positive\n",
      "588 reduce\n",
      "589 fulfil\n",
      "590 visi\n",
      "591 connection\n",
      "592 electrify\n",
      "593 household\n",
      "594 inflation\n",
      "595 poors\n",
      "596 september\n",
      "597 villages\n",
      "598 point\n",
      "599 engage\n",
      "600 message\n",
      "601 outreach\n",
      "602 propagate\n",
      "603 actively\n",
      "604 admi\n",
      "605 build\n",
      "606 cure\n",
      "607 diseases\n",
      "608 faeces\n",
      "609 toilets\n",
      "610 vulnerable\n",
      "611 arora\n",
      "612 ayush\n",
      "613 currently\n",
      "614 financial\n",
      "615 journalist\n",
      "616 story\n",
      "617 ayushm\n",
      "618 bhushan\n",
      "619 crores\n",
      "620 econo\n",
      "621 irrespective\n",
      "622 prophesy\n",
      "623 write\n",
      "624 launche\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs['text'])\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x119cad358>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(51, 2)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs['text']]\n",
    "bow_corpus[410]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 0 (\"ayushman\") appears 1 time.\n",
      "Word 2 (\"bharat\") appears 1 time.\n",
      "Word 13 (\"baby\") appears 1 time.\n",
      "Word 27 (\"days\") appears 1 time.\n",
      "Word 28 (\"karishma\") appears 1 time.\n",
      "Word 29 (\"launch\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_43 = bow_corpus[23]\n",
    "for i in range(len(bow_doc_43)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_43[i][0], \n",
    "                                               dictionary[bow_doc_43[i][0]], \n",
    "bow_doc_43[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.23238012033382507),\n",
      " (1, 0.28614497850250775),\n",
      " (2, 0.24975192180550712),\n",
      " (3, 0.36106939803105237),\n",
      " (4, 0.7379085825173771),\n",
      " (5, 0.3561801821530513)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.118*\"ayushman\" + 0.114*\"bharat\" + 0.090*\"haryana\" + 0.087*\"india\" + 0.087*\"beneficiary\" + 0.086*\"newborn\" + 0.084*\"yojana\" + 0.068*\"namo\" + 0.022*\"delhi\" + 0.018*\"health\"\n",
      "Topic: 1 \n",
      "Words: 0.125*\"ayushman\" + 0.110*\"baby\" + 0.101*\"bharat\" + 0.077*\"karishma\" + 0.064*\"haryana\" + 0.060*\"beneficiary\" + 0.046*\"scheme\" + 0.040*\"claim\" + 0.031*\"karnal\" + 0.031*\"proud\"\n",
      "Topic: 2 \n",
      "Words: 0.122*\"ayushmanbharat\" + 0.077*\"beneficiary\" + 0.074*\"india\" + 0.068*\"karishma\" + 0.067*\"karnal\" + 0.054*\"review\" + 0.041*\"modicare\" + 0.037*\"birth\" + 0.036*\"start\" + 0.035*\"claim\"\n",
      "Topic: 3 \n",
      "Words: 0.088*\"section\" + 0.088*\"claim\" + 0.088*\"bear\" + 0.088*\"caesarean\" + 0.087*\"ayushmanbharat\" + 0.086*\"baby\" + 0.085*\"hospital\" + 0.085*\"raise\" + 0.084*\"chawla\" + 0.084*\"kalpana\"\n",
      "Topic: 4 \n",
      "Words: 0.091*\"bear\" + 0.078*\"haryana\" + 0.072*\"beneficiary\" + 0.060*\"karishma\" + 0.058*\"namo\" + 0.052*\"karnal\" + 0.046*\"days\" + 0.045*\"govt\" + 0.045*\"chawla\" + 0.045*\"kalpana\"\n",
      "Topic: 5 \n",
      "Words: 0.120*\"ayushmanbharat\" + 0.116*\"claim\" + 0.116*\"start\" + 0.116*\"modicare\" + 0.115*\"birth\" + 0.115*\"great\" + 0.115*\"fittingly\" + 0.021*\"bharat\" + 0.021*\"ayushman\" + 0.021*\"beneficiary\"\n",
      "Topic: 6 \n",
      "Words: 0.106*\"beneficiary\" + 0.106*\"india\" + 0.104*\"ayushman\" + 0.101*\"bharat\" + 0.100*\"haryana\" + 0.096*\"yojana\" + 0.091*\"newborn\" + 0.037*\"namo\" + 0.031*\"bear\" + 0.021*\"ayushmanbharat\"\n",
      "Topic: 7 \n",
      "Words: 0.130*\"bharat\" + 0.130*\"ayushman\" + 0.089*\"yojana\" + 0.080*\"hospital\" + 0.070*\"pilot\" + 0.070*\"tomorrow\" + 0.070*\"balrampur\" + 0.070*\"inaugurate\" + 0.020*\"india\" + 0.020*\"beneficiary\"\n",
      "Topic: 8 \n",
      "Words: 0.056*\"modi\" + 0.055*\"ayushman\" + 0.055*\"bharat\" + 0.039*\"plan\" + 0.038*\"overnight\" + 0.038*\"typical\" + 0.037*\"promise\" + 0.036*\"ayushma\" + 0.035*\"sound\" + 0.035*\"target\"\n",
      "Topic: 9 \n",
      "Words: 0.104*\"bear\" + 0.084*\"ayushmanbharat\" + 0.081*\"baby\" + 0.066*\"benefit\" + 0.052*\"govt\" + 0.050*\"modicare\" + 0.046*\"claim\" + 0.041*\"scheme\" + 0.040*\"raise\" + 0.037*\"caesarean\"\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.065*\"inaugurate\" + 0.065*\"pilot\" + 0.065*\"tomorrow\" + 0.065*\"balrampur\" + 0.052*\"hospital\" + 0.044*\"govt\" + 0.044*\"bharat\" + 0.042*\"ayushman\" + 0.041*\"yojana\" + 0.036*\"bear\"\n",
      "Topic: 1 Word: 0.057*\"yojna\" + 0.056*\"pradhan\" + 0.056*\"mantri\" + 0.054*\"baby\" + 0.054*\"namo\" + 0.051*\"angel\" + 0.044*\"karishma\" + 0.038*\"ayushman\" + 0.031*\"scheme\" + 0.029*\"beneficiary\"\n",
      "Topic: 2 Word: 0.123*\"newborn\" + 0.116*\"india\" + 0.108*\"yojana\" + 0.097*\"namo\" + 0.090*\"haryana\" + 0.084*\"bharat\" + 0.084*\"beneficiary\" + 0.077*\"ayushman\" + 0.018*\"independence\" + 0.015*\"bear\"\n",
      "Topic: 3 Word: 0.101*\"karnal\" + 0.091*\"karishma\" + 0.070*\"india\" + 0.066*\"ayushmanbharat\" + 0.056*\"beneficiary\" + 0.044*\"review\" + 0.025*\"today\" + 0.025*\"baby\" + 0.023*\"raise\" + 0.023*\"scheme\"\n",
      "Topic: 4 Word: 0.089*\"bharat\" + 0.084*\"ayushman\" + 0.082*\"newborn\" + 0.077*\"india\" + 0.072*\"yojana\" + 0.066*\"haryana\" + 0.058*\"beneficiary\" + 0.053*\"namo\" + 0.045*\"health\" + 0.038*\"modi\"\n",
      "Topic: 5 Word: 0.053*\"baby\" + 0.050*\"karishma\" + 0.045*\"bear\" + 0.037*\"kalpana\" + 0.037*\"chawla\" + 0.034*\"beneficiary\" + 0.033*\"hospital\" + 0.033*\"ayushman\" + 0.032*\"caesarean\" + 0.032*\"days\"\n",
      "Topic: 6 Word: 0.051*\"congrats\" + 0.051*\"proud\" + 0.051*\"arrive\" + 0.044*\"scheme\" + 0.037*\"karishma\" + 0.034*\"karnal\" + 0.027*\"bharat\" + 0.027*\"promise\" + 0.026*\"typical\" + 0.026*\"overnight\"\n",
      "Topic: 7 Word: 0.068*\"claim\" + 0.068*\"ayushmanbharat\" + 0.063*\"fittingly\" + 0.063*\"great\" + 0.062*\"birth\" + 0.062*\"hary\" + 0.062*\"start\" + 0.061*\"raise\" + 0.061*\"caesarean\" + 0.060*\"section\"\n",
      "Topic: 8 Word: 0.283*\"namo\" + 0.053*\"benefit\" + 0.045*\"bear\" + 0.043*\"govt\" + 0.039*\"beneficiary\" + 0.031*\"ayushmanbharat\" + 0.029*\"baby\" + 0.028*\"india\" + 0.026*\"karnal\" + 0.025*\"modicare\"\n",
      "Topic: 9 Word: 0.044*\"haryana\" + 0.042*\"beneficiary\" + 0.040*\"thankyou\" + 0.038*\"scheme\" + 0.038*\"karnal\" + 0.038*\"bharat\" + 0.036*\"demand\" + 0.036*\"ayushman\" + 0.036*\"karishma\" + 0.035*\"govt\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.8874953389167786\t \n",
      "Topic: 0.120*\"ayushmanbharat\" + 0.116*\"claim\" + 0.116*\"start\" + 0.116*\"modicare\" + 0.115*\"birth\" + 0.115*\"great\" + 0.115*\"fittingly\" + 0.021*\"bharat\" + 0.021*\"ayushman\" + 0.021*\"beneficiary\"\n",
      "\n",
      "Score: 0.012501604855060577\t \n",
      "Topic: 0.122*\"ayushmanbharat\" + 0.077*\"beneficiary\" + 0.074*\"india\" + 0.068*\"karishma\" + 0.067*\"karnal\" + 0.054*\"review\" + 0.041*\"modicare\" + 0.037*\"birth\" + 0.036*\"start\" + 0.035*\"claim\"\n",
      "\n",
      "Score: 0.012500970624387264\t \n",
      "Topic: 0.104*\"bear\" + 0.084*\"ayushmanbharat\" + 0.081*\"baby\" + 0.066*\"benefit\" + 0.052*\"govt\" + 0.050*\"modicare\" + 0.046*\"claim\" + 0.041*\"scheme\" + 0.040*\"raise\" + 0.037*\"caesarean\"\n",
      "\n",
      "Score: 0.012500911951065063\t \n",
      "Topic: 0.088*\"section\" + 0.088*\"claim\" + 0.088*\"bear\" + 0.088*\"caesarean\" + 0.087*\"ayushmanbharat\" + 0.086*\"baby\" + 0.085*\"hospital\" + 0.085*\"raise\" + 0.084*\"chawla\" + 0.084*\"kalpana\"\n",
      "\n",
      "Score: 0.012500474229454994\t \n",
      "Topic: 0.091*\"bear\" + 0.078*\"haryana\" + 0.072*\"beneficiary\" + 0.060*\"karishma\" + 0.058*\"namo\" + 0.052*\"karnal\" + 0.046*\"days\" + 0.045*\"govt\" + 0.045*\"chawla\" + 0.045*\"kalpana\"\n",
      "\n",
      "Score: 0.012500256299972534\t \n",
      "Topic: 0.125*\"ayushman\" + 0.110*\"baby\" + 0.101*\"bharat\" + 0.077*\"karishma\" + 0.064*\"haryana\" + 0.060*\"beneficiary\" + 0.046*\"scheme\" + 0.040*\"claim\" + 0.031*\"karnal\" + 0.031*\"proud\"\n",
      "\n",
      "Score: 0.012500176206231117\t \n",
      "Topic: 0.118*\"ayushman\" + 0.114*\"bharat\" + 0.090*\"haryana\" + 0.087*\"india\" + 0.087*\"beneficiary\" + 0.086*\"newborn\" + 0.084*\"yojana\" + 0.068*\"namo\" + 0.022*\"delhi\" + 0.018*\"health\"\n",
      "\n",
      "Score: 0.012500167824327946\t \n",
      "Topic: 0.106*\"beneficiary\" + 0.106*\"india\" + 0.104*\"ayushman\" + 0.101*\"bharat\" + 0.100*\"haryana\" + 0.096*\"yojana\" + 0.091*\"newborn\" + 0.037*\"namo\" + 0.031*\"bear\" + 0.021*\"ayushmanbharat\"\n",
      "\n",
      "Score: 0.012500050477683544\t \n",
      "Topic: 0.130*\"bharat\" + 0.130*\"ayushman\" + 0.089*\"yojana\" + 0.080*\"hospital\" + 0.070*\"pilot\" + 0.070*\"tomorrow\" + 0.070*\"balrampur\" + 0.070*\"inaugurate\" + 0.020*\"india\" + 0.020*\"beneficiary\"\n",
      "\n",
      "Score: 0.012500029988586903\t \n",
      "Topic: 0.056*\"modi\" + 0.055*\"ayushman\" + 0.055*\"bharat\" + 0.039*\"plan\" + 0.038*\"overnight\" + 0.038*\"typical\" + 0.037*\"promise\" + 0.036*\"ayushma\" + 0.035*\"sound\" + 0.035*\"target\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[405]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.887495219707489\t \n",
      "Topic: 0.130*\"bharat\" + 0.130*\"ayushman\" + 0.089*\"yojana\" + 0.080*\"hospital\" + 0.070*\"pilot\" + 0.070*\"tomorrow\" + 0.070*\"balrampur\" + 0.070*\"inaugurate\" + 0.020*\"india\" + 0.020*\"beneficiary\"\n",
      "\n",
      "Score: 0.012501038610935211\t \n",
      "Topic: 0.088*\"section\" + 0.088*\"claim\" + 0.088*\"bear\" + 0.088*\"caesarean\" + 0.087*\"ayushmanbharat\" + 0.086*\"baby\" + 0.085*\"hospital\" + 0.085*\"raise\" + 0.084*\"chawla\" + 0.084*\"kalpana\"\n",
      "\n",
      "Score: 0.012500951997935772\t \n",
      "Topic: 0.118*\"ayushman\" + 0.114*\"bharat\" + 0.090*\"haryana\" + 0.087*\"india\" + 0.087*\"beneficiary\" + 0.086*\"newborn\" + 0.084*\"yojana\" + 0.068*\"namo\" + 0.022*\"delhi\" + 0.018*\"health\"\n",
      "\n",
      "Score: 0.012500770390033722\t \n",
      "Topic: 0.056*\"modi\" + 0.055*\"ayushman\" + 0.055*\"bharat\" + 0.039*\"plan\" + 0.038*\"overnight\" + 0.038*\"typical\" + 0.037*\"promise\" + 0.036*\"ayushma\" + 0.035*\"sound\" + 0.035*\"target\"\n",
      "\n",
      "Score: 0.012500456534326077\t \n",
      "Topic: 0.091*\"bear\" + 0.078*\"haryana\" + 0.072*\"beneficiary\" + 0.060*\"karishma\" + 0.058*\"namo\" + 0.052*\"karnal\" + 0.046*\"days\" + 0.045*\"govt\" + 0.045*\"chawla\" + 0.045*\"kalpana\"\n",
      "\n",
      "Score: 0.01250036433339119\t \n",
      "Topic: 0.125*\"ayushman\" + 0.110*\"baby\" + 0.101*\"bharat\" + 0.077*\"karishma\" + 0.064*\"haryana\" + 0.060*\"beneficiary\" + 0.046*\"scheme\" + 0.040*\"claim\" + 0.031*\"karnal\" + 0.031*\"proud\"\n",
      "\n",
      "Score: 0.012500355020165443\t \n",
      "Topic: 0.104*\"bear\" + 0.084*\"ayushmanbharat\" + 0.081*\"baby\" + 0.066*\"benefit\" + 0.052*\"govt\" + 0.050*\"modicare\" + 0.046*\"claim\" + 0.041*\"scheme\" + 0.040*\"raise\" + 0.037*\"caesarean\"\n",
      "\n",
      "Score: 0.012500351294875145\t \n",
      "Topic: 0.120*\"ayushmanbharat\" + 0.116*\"claim\" + 0.116*\"start\" + 0.116*\"modicare\" + 0.115*\"birth\" + 0.115*\"great\" + 0.115*\"fittingly\" + 0.021*\"bharat\" + 0.021*\"ayushman\" + 0.021*\"beneficiary\"\n",
      "\n",
      "Score: 0.012500329874455929\t \n",
      "Topic: 0.106*\"beneficiary\" + 0.106*\"india\" + 0.104*\"ayushman\" + 0.101*\"bharat\" + 0.100*\"haryana\" + 0.096*\"yojana\" + 0.091*\"newborn\" + 0.037*\"namo\" + 0.031*\"bear\" + 0.021*\"ayushmanbharat\"\n",
      "\n",
      "Score: 0.012500141747295856\t \n",
      "Topic: 0.122*\"ayushmanbharat\" + 0.077*\"beneficiary\" + 0.074*\"india\" + 0.068*\"karishma\" + 0.067*\"karnal\" + 0.054*\"review\" + 0.041*\"modicare\" + 0.037*\"birth\" + 0.036*\"start\" + 0.035*\"claim\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[405]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
