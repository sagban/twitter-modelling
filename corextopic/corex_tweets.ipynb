{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import corextopic as ct\n",
    "import vis_topic as vt # jupyter notebooks will complain matplotlib is being loaded twice\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "import csv\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../CSV/big_data.csv\"\n",
    "# 15 Days blocks\n",
    "file1 = \"../CSV/big_data1.csv\"\n",
    "file2 = \"../CSV/big_data2.csv\"\n",
    "file3 = \"../CSV/big_data3.csv\"\n",
    "file4 = \"../CSV/big_data4.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    result = re.sub(r\"http\\S+\", \"\", text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_user(t):\n",
    "    t = re.sub('@[^\\s]+','',t)\n",
    "    return re.sub('@[^\\s]+','',t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_hash(t):\n",
    "    return re.sub('#[^\\s]+','',t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_RT(t):\n",
    "    return re.sub('RT','',t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellcheck(text):\n",
    "    return  re.sub(r'[^a-zA-Z ]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = remove_url(text)\n",
    "    text = rem_user(text)\n",
    "    text = rem_hash(text)\n",
    "    text = rem_RT(text)\n",
    "    text = spellcheck(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_word(word):\n",
    "    if not word.isdigit() and len(word) > 3 and word not in gensim.parsing.preprocessing.STOPWORDS:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output(topics, output_file):\n",
    "    with open(output_file, 'w') as writeFile:\n",
    "        writer = csv.writer(writeFile)\n",
    "        writer.writerows([['Topic','Values']])\n",
    "        total = []\n",
    "        for n,topic in enumerate(topics):\n",
    "            topic_words,_ = zip(*topic)\n",
    "            topic_list = list(topic_words)\n",
    "            topic_list.insert(0, n+1)\n",
    "            total.append(topic_list)\n",
    "        writer.writerows(list(total))\n",
    "    writeFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8950\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://t.co/BJJ43TYjYl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @sujakrao: Watch | Does India Have the Fund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @dm_ghaziabad: _Â_¢____ _Ñ___Ï_À_ø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @iScrew: Here's a (partial) list of all the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @iScrew: Here's a (partial) list of all the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                            https://t.co/BJJ43TYjYl\n",
       "1  RT @sujakrao: Watch | Does India Have the Fund...\n",
       "2  RT @dm_ghaziabad: _Â_¢____ _Ñ___Ï_À_ø...\n",
       "3  RT @iScrew: Here's a (partial) list of all the...\n",
       "4  RT @iScrew: Here's a (partial) list of all the..."
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the data\n",
    "\n",
    "data = pd.read_csv(file4, error_bad_lines=False, encoding='latin-1');\n",
    "document = data[['text']]\n",
    "print(len(document))\n",
    "document.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch  Does India Have the Funds to Run the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ayushman Bharat scheme of Ministry of h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heres a partial list of all the preexisting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heres a partial list of all the preexisting ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                                   \n",
       "1    Watch  Does India Have the Funds to Run the ...\n",
       "2         Ayushman Bharat scheme of Ministry of h...\n",
       "3    Heres a partial list of all the preexisting ...\n",
       "4    Heres a partial list of all the preexisting ..."
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = document\n",
    "processed_docs['text'] = processed_docs['text'].map(preprocess)\n",
    "processed_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8950, 2988)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform tweets data into a sparse matrix\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=20000, binary=True)\n",
    "doc_word = vectorizer.fit_transform(processed_docs['text'])\n",
    "doc_word = ss.csr_matrix(doc_word)\n",
    "doc_word.shape # n_docs x m_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2988"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get words that label the columns (needed to extract readable topics and make anchoring easier)\n",
    "words = list(np.asarray(vectorizer.get_feature_names()))\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_digit_inds = [ind for ind,word in enumerate(words) if is_valid_word(word)]\n",
    "doc_word = doc_word[:,not_digit_inds]\n",
    "words = [word for ind,word in enumerate(words) if is_valid_word(word)]\n",
    "\n",
    "doc_word.shape[1] == len(words) # n_docs x m_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2660"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CorEx topic model with 50 topics\n",
    "topic_model = ct.Corex(n_hidden=20, words=words, max_iter=200, verbose=False, seed=1)\n",
    "topic_model.fit(doc_word, words=words);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('consider', 0.27025435896443695),\n",
       " ('talk', 0.2675288596829946),\n",
       " ('want', 0.2658126091051127),\n",
       " ('dhan', 0.16403645993721658),\n",
       " ('importantif', 0.1630687675684841),\n",
       " ('padhao', 0.1630687675684841),\n",
       " ('record', 0.16197536850135028),\n",
       " ('swacch', 0.16197536850135028),\n",
       " ('ujjwala', 0.16066301586308157),\n",
       " ('beti', 0.15692797033679637)]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a single topic from CorEx topic model\n",
    "topic_model.get_topics(topic=1, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: unparalleled,enthusiasm,seeing,pmjayayushman,karyakarta,ghazipur,asked,ayushman,narendramodi,karyak\n",
      "2: consider,talk,want,dhan,importantif,padhao,record,swacch,ujjwala,beti\n",
      "3: wait,benefitting,lacs,seen,comment,liberandu,tragedy,scheme,mantri,pradhan\n",
      "4: benefit,going,providing,country,coverage,medical,people,admissions,approved,weeks\n",
      "5: hospitals,treatment,railway,anil,today,soon,team,india,free,alag\n",
      "6: private,hospital,players,doubts,viability,owners,district,especially,program,demand\n",
      "7: universal,step,major,provision,components,healthcar,complete,families,initiative,wonderful\n",
      "8: kangra,college,addresses,convocation,rajendra,prasad,says,presents,lies,halftruths\n",
      "9: beneficiaries,sipping,wine,star,intellectual,letters,send,unaware,schemeas,reports\n",
      "10: launch,lucknow,gift,swach,treated,denied,holder,success,card,worlds\n",
      "11: modicare,jobs,benefits,create,days,modis,single,rupee,charging,start\n",
      "12: services,live,work,centre,video,organise,workshop,thanks,traning,mpprovide\n",
      "13: benefitted,lakh,nadda,ambitious,benefited,shri,crosses,subscribers,cards,distributed\n",
      "14: world,biggest,model,niti,develop,parts,systems,aayog,destined,concession\n",
      "15: namo,bharatvia,antyodayvia,beautiful,giftvia,heartiest,shaer,rapidly,namaskarmera,kishan\n",
      "16: crore,yojana,cover,indians,mandatory,lives,according,inrstatue,pioneering,unity\n",
      "17: congress,data,years,website,reservation,dalits,link,fake,collect,individuals\n",
      "18: government,launched,healthcare,poor,quality,life,lakhs,changing,getting,accidental\n",
      "19: bharat,ministry,governor,critical,condition,doesnt,bhara,corruption,bharatpradhan,hindu\n",
      "20: month,health,cracks,appearing,predictable,thank,reaches,details,whats,earns\n"
     ]
    }
   ],
   "source": [
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_ = zip(*topic)\n",
    "    print('{}: '.format(n+1) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"results_corex_tweets\"+str(4)+\".csv\"\n",
    "save_output(topics, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
